{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcvMbe-JowiY"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from util import view_10\n",
    "from data import fetch_dataset, data_to_tensor, iid_partition_loader, noniid_partition_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"| using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoZbOl8Gt3GV"
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "bsz = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VixfemygHq3q"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.py\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNISTFromRaw(Dataset):\n",
    "    def __init__(self, images_u8: np.ndarray, labels_u8: np.ndarray, normalize=True):\n",
    "        \"\"\"\n",
    "        images_u8: uint8 array of shape (N, 28, 28)\n",
    "        labels_u8: uint8 array of shape (N,)\n",
    "        \"\"\"\n",
    "        assert images_u8.ndim == 3 and images_u8.shape[1:] == (28, 28)\n",
    "        assert labels_u8.ndim == 1 and images_u8.shape[0] == labels_u8.shape[0]\n",
    "\n",
    "        self.images = images_u8\n",
    "        self.labels = labels_u8\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # MNIST normalization constants (same as torchvision example)\n",
    "        self.mean = 0.1307\n",
    "        self.std  = 0.3081\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]  # (28, 28) uint8\n",
    "        y = int(self.labels[idx])\n",
    "\n",
    "        # convert to float tensor in [0,1], shape (1,28,28)\n",
    "        x = torch.from_numpy(img).float().unsqueeze(0) / 255.0\n",
    "\n",
    "        if self.normalize:\n",
    "            x = (x - self.mean) / self.std\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def _read_idx_gz(path: str) -> np.ndarray:\n",
    "    with gzip.open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # IDX format: big-endian\n",
    "    # first 4 bytes: magic number\n",
    "    magic = int.from_bytes(data[0:4], byteorder=\"big\")\n",
    "    if magic == 2051:  # images\n",
    "        n = int.from_bytes(data[4:8], \"big\")\n",
    "        rows = int.from_bytes(data[8:12], \"big\")\n",
    "        cols = int.from_bytes(data[12:16], \"big\")\n",
    "        arr = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "        arr = arr.reshape(n, rows, cols)\n",
    "        return arr\n",
    "    elif magic == 2049:  # labels\n",
    "        n = int.from_bytes(data[4:8], \"big\")\n",
    "        arr = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        arr = arr.reshape(n,)\n",
    "        return arr\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unknown IDX magic {magic} in file: {path}\")\n",
    "\n",
    "\n",
    "def fetch_dataset(root=\"./data\"):\n",
    "    \"\"\"\n",
    "    Expects:\n",
    "      {root}/MNIST/raw/train-images-idx3-ubyte.gz\n",
    "      {root}/MNIST/raw/train-labels-idx1-ubyte.gz\n",
    "      {root}/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
    "      {root}/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
    "    \"\"\"\n",
    "    raw_dir = os.path.join(root, \"MNIST\", \"raw\")\n",
    "    required = {\n",
    "        \"train_images\": os.path.join(raw_dir, \"train-images-idx3-ubyte.gz\"),\n",
    "        \"train_labels\": os.path.join(raw_dir, \"train-labels-idx1-ubyte.gz\"),\n",
    "        \"test_images\":  os.path.join(raw_dir, \"t10k-images-idx3-ubyte.gz\"),\n",
    "        \"test_labels\":  os.path.join(raw_dir, \"t10k-labels-idx1-ubyte.gz\"),\n",
    "    }\n",
    "    missing = [p for p in required.values() if not os.path.exists(p)]\n",
    "    if missing:\n",
    "        raise RuntimeError(\n",
    "            \"MNIST raw .gz files missing. Expected them in:\\n\"\n",
    "            f\"  {raw_dir}\\n\\nMissing:\\n  - \" + \"\\n  - \".join(missing)\n",
    "        )\n",
    "\n",
    "    Xtr = _read_idx_gz(required[\"train_images\"])\n",
    "    ytr = _read_idx_gz(required[\"train_labels\"])\n",
    "    Xte = _read_idx_gz(required[\"test_images\"])\n",
    "    yte = _read_idx_gz(required[\"test_labels\"])\n",
    "\n",
    "    train_data = MNISTFromRaw(Xtr, ytr, normalize=True)\n",
    "    test_data  = MNISTFromRaw(Xte, yte, normalize=True)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfPfvy-7sf-D"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = fetch_dataset()\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 1000, shuffle=False) # inference bsz=1000\n",
    "debug_loader = torch.utils.data.DataLoader(train_data, bsz)\n",
    "img, label = next(iter(debug_loader))\n",
    "view_10(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4mN1wUr4izX"
   },
   "outputs": [],
   "source": [
    "# get client dataloaders\n",
    "iid_client_train_loader = iid_partition_loader(train_data, bsz = bsz)\n",
    "noniid_client_train_loader = noniid_partition_loader(train_data, bsz = bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls_0Ke21Govu"
   },
   "outputs": [],
   "source": [
    "# iid\n",
    "label_dist = torch.zeros(10)\n",
    "for (x,y) in iid_client_train_loader[25]:\n",
    "    label_dist+= torch.sum(F.one_hot(y, num_classes=10), dim=0)\n",
    "print(\"iid: \", label_dist)\n",
    "view_10(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqZgr4FO41Bi"
   },
   "outputs": [],
   "source": [
    "# non-iid\n",
    "label_dist = torch.zeros(10)\n",
    "for (x,y) in noniid_client_train_loader[25]:\n",
    "    label_dist+= torch.sum(F.one_hot(y,num_classes=10), dim=0)\n",
    "print(\"non-iid: \", label_dist)\n",
    "view_10(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cAwYqdeHvcY"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fully connected NN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def num_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.out = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)        # [B, 784]\n",
    "        x = F.relu(self.fc1(x)) # [B, 200]\n",
    "        x = F.relu(self.fc2(x)) # [B, 200]\n",
    "        x = self.out(x)         # [B, 10]\n",
    "        return x\n",
    "\n",
    "m = MLP()\n",
    "print(m)\n",
    "print(\"Trainable params:\", num_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jefi6wlYpXYa"
   },
   "outputs": [],
   "source": [
    "# define cnn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.conv1(x), 2, 2) # [B x 32 x 12 x 12]\n",
    "        x = F.max_pool2d(self.conv2(x), 2, 2) # [B x 64 x 4 x 4]\n",
    "        x = x.flatten(1) # [B x 1024]\n",
    "        x = F.relu(self.fc(x)) # [B x 512]\n",
    "        x = self.out(x) # [B x 10]\n",
    "        return x\n",
    "\n",
    "print(CNN())\n",
    "print(num_params(CNN()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6Tmim2lHz4j"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4mTFWgx0gmq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def validate(model):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (t, (x,y)) in enumerate(test_loader):\n",
    "            x = x.to(cuda)\n",
    "            y = y.to(cuda)\n",
    "            out = model(x)\n",
    "            correct += torch.sum(torch.argmax(out, dim=1) == y).item()\n",
    "            total += x.shape[0]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YDOK1S0H_Xe"
   },
   "outputs": [],
   "source": [
    "def train_client(id, client_loader, global_model, num_local_epochs, lr):\n",
    "    local_model = copy.deepcopy(global_model)\n",
    "    local_model = local_model.to(device)\n",
    "    local_model.train()\n",
    "    optimizer = torch.optim.SGD(local_model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_local_epochs):\n",
    "        for (i, (x,y)) in enumerate(client_loader):\n",
    "            x = x.to(gpu)\n",
    "            y = y.to(gpu)\n",
    "            optimizer.zero_grad()\n",
    "            out = local_model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return local_model\n",
    "\n",
    "def running_model_avg(current, next, scale):\n",
    "    if current == None:\n",
    "        current = next\n",
    "        for key in current:\n",
    "            current[key] = current[key] * scale\n",
    "    else:\n",
    "        for key in current:\n",
    "            current[key] = current[key] + (next[key] * scale)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pJgWgjM-Pv4R"
   },
   "outputs": [],
   "source": [
    "def fed_avg_experiment(global_model, num_clients_per_round, num_local_epochs, lr, client_train_loader, max_rounds, filename):\n",
    "    round_accuracy = []\n",
    "    for t in range(max_rounds):\n",
    "        print(\"starting round {}\".format(t))\n",
    "\n",
    "        # choose clients\n",
    "        clients = np.random.choice(np.arange(100), num_clients_per_round, replace = False)\n",
    "        print(\"clients: \", clients)\n",
    "\n",
    "        global_model.eval()\n",
    "        global_model = global_model.to(cuda)\n",
    "        running_avg = None\n",
    "\n",
    "        for i,c in enumerate(clients):\n",
    "            # train local client\n",
    "            print(\"round {}, starting client {}/{}, id: {}\".format(t, i+1,num_clients_per_round, c))\n",
    "            local_model = train_client(c, client_train_loader[c], global_model, num_local_epochs, lr)\n",
    "\n",
    "            # add local model parameters to running average\n",
    "            running_avg = running_model_avg(running_avg, local_model.state_dict(), 1/num_clients_per_round)\n",
    "        \n",
    "        # set global model parameters for the next step\n",
    "        global_model.load_state_dict(running_avg)\n",
    "\n",
    "        # validate\n",
    "        val_acc = validate(global_model)\n",
    "        print(\"round {}, validation acc: {}\".format(t, val_acc))\n",
    "        round_accuracy.append(val_acc)\n",
    "\n",
    "        if (t % 10 == 0):\n",
    "          np.save(filename+'_{}'.format(t)+'.npy', np.array(round_accuracy))\n",
    "\n",
    "    return np.array(round_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrmY-TPnGI77"
   },
   "source": [
    " ## MLP experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mwymk72xlaDP"
   },
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "print(mlp)\n",
    "print(\"total params: \", num_params(mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDjaFBJAjeHC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MLP - iid - m=10 experiment\n",
    "mlp_iid_m10 = copy.deepcopy(mlp)\n",
    "acc_mlp_iid_m10 = fed_avg_experiment(mlp_iid_m10, num_clients_per_round=10, \n",
    "                                 num_local_epochs=1,\n",
    "                                 lr=0.05,\n",
    "                                 client_train_loader = iid_client_train_loader,\n",
    "                                 max_rounds=100,\n",
    "                                 filename='./acc_mlp_iid_m10')\n",
    "print(acc_mlp_iid_m10)\n",
    "np.save('./acc_mlp_iid_m10.npy', acc_mlp_iid_m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curve(acc, ylabel=\"Test Accuracy\", title=\"FedAvg (MLP)\"):\n",
    "    acc = np.asarray(acc)\n",
    "\n",
    "    fig = plt.figure(figsize=(6.2, 3.6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(1, len(acc)+1), acc, linewidth=2)\n",
    "\n",
    "    ax.set_xlabel(\"Communication Round\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Example usage\n",
    "fig = plot_curve(acc_mlp_iid_m10, title=\"FedAvg (MLP) | IID | m=10\")\n",
    "fig.savefig(\"acc_mlp_iid_m10.pdf\")   # best for papers\n",
    "fig.savefig(\"acc_mlp_iid_m10.svg\")   # vector\n",
    "fig.savefig(\"acc_mlp_iid_m10.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_std(curves, title=\"FedAvg\"):\n",
    "    curves = [np.asarray(c) for c in curves]\n",
    "    T = min(len(c) for c in curves)\n",
    "    M = np.stack([c[:T] for c in curves], axis=0)\n",
    "    mean = M.mean(axis=0)\n",
    "    std  = M.std(axis=0)\n",
    "\n",
    "    x = np.arange(1, T+1)\n",
    "    fig = plt.figure(figsize=(6.2, 3.6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, mean, linewidth=2)\n",
    "    ax.fill_between(x, mean-std, mean+std, alpha=0.2)\n",
    "\n",
    "    ax.set_xlabel(\"Communication Round\")\n",
    "    ax.set_ylabel(\"Test Accuracy\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Helpers: flatten params / set params ----\n",
    "def flatten_params(model: torch.nn.Module) -> torch.Tensor:\n",
    "    return torch.cat([p.detach().flatten() for p in model.parameters()])\n",
    "\n",
    "def set_params_from_flat(model: torch.nn.Module, flat: torch.Tensor):\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            n = p.numel()\n",
    "            p.copy_(flat[idx:idx+n].view_as(p))\n",
    "            idx += n\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loss(model, data_loader, device, max_batches=10):\n",
    "    model.eval()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    total_loss, total_n = 0.0, 0\n",
    "    for b, (x, y) in enumerate(data_loader):\n",
    "        if b >= max_batches:\n",
    "            break\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_n += bs\n",
    "    return total_loss / max(1, total_n)\n",
    "\n",
    "def random_direction_like(w: torch.Tensor, seed=0):\n",
    "    # reproducible without generator= (works across more torch versions)\n",
    "    prev_state = torch.random.get_rng_state()\n",
    "    torch.manual_seed(seed)\n",
    "    d = torch.randn_like(w)\n",
    "    torch.random.set_rng_state(prev_state)\n",
    "\n",
    "    d = d / (d.norm() + 1e-12)   # unit direction\n",
    "    return d\n",
    "\n",
    "def loss_surface_2d(model, loader, device, span=1.0, steps=41, seed1=0, seed2=1, max_batches=10):\n",
    "    model = model.to(device)\n",
    "    w0 = flatten_params(model).to(cuda)\n",
    "\n",
    "    d1 = random_direction_like(w0, seed=seed1)\n",
    "    d2 = random_direction_like(w0, seed=seed2)\n",
    "\n",
    "    # Grid in (alpha, beta)\n",
    "    alphas = torch.linspace(-span, span, steps, device=device)\n",
    "    betas  = torch.linspace(-span, span, steps, device=device)\n",
    "\n",
    "    Z = np.zeros((steps, steps), dtype=np.float64)\n",
    "\n",
    "    for i, a in enumerate(alphas):\n",
    "        for j, b in enumerate(betas):\n",
    "            w = w0 + a * d1 + b * d2\n",
    "            set_params_from_flat(model, w)\n",
    "            Z[i, j] = eval_loss(model, loader, device, max_batches=max_batches)\n",
    "\n",
    "    # restore original weights\n",
    "    set_params_from_flat(model, w0)\n",
    "    return alphas.detach().cpu().numpy(), betas.detach().cpu().numpy(), Z\n",
    "\n",
    "def plot_surface_and_contour(alphas, betas, Z, title=\"Loss Surface\"):\n",
    "    A, B = np.meshgrid(betas, alphas)  # note order for plotting\n",
    "    # 3D surface\n",
    "    fig1 = plt.figure(figsize=(7.0, 4.8))\n",
    "    ax3d = fig1.add_subplot(111, projection=\"3d\")\n",
    "    ax3d.plot_surface(A, B, Z, rstride=1, cstride=1, linewidth=0, antialiased=True)\n",
    "    ax3d.set_xlabel(r\"$\\beta$\")\n",
    "    ax3d.set_ylabel(r\"$\\alpha$\")\n",
    "    ax3d.set_zlabel(\"Loss\")\n",
    "    ax3d.set_title(title)\n",
    "    fig1.tight_layout()\n",
    "\n",
    "    # 2D contour\n",
    "    fig2 = plt.figure(figsize=(6.2, 4.2))\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    cs = ax2.contour(A, B, Z, levels=25)\n",
    "    ax2.clabel(cs, inline=True, fontsize=8)\n",
    "    ax2.set_xlabel(r\"$\\beta$\")\n",
    "    ax2.set_ylabel(r\"$\\alpha$\")\n",
    "    ax2.set_title(title + \" (Contour)\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    fig2.tight_layout()\n",
    "\n",
    "    return fig1, fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Use your final trained model (after fed_avg_experiment)\n",
    "final_model = mlp_iid_m10  # this should contain the final global weights\n",
    "\n",
    "alphas, betas, Z = loss_surface_2d(\n",
    "    model=final_model,\n",
    "    loader=test_loader,\n",
    "    device=device,\n",
    "    span=1.0,         # try 0.5, 1.0, 2.0\n",
    "    steps=41,         # 31/41 good; larger is slower\n",
    "    max_batches=10    # increase for smoother surface (slower)\n",
    ")\n",
    "\n",
    "fig3d, fig2d = plot_surface_and_contour(alphas, betas, Z, title=\"FedAvg MLP | IID m=10 | Loss Surface\")\n",
    "\n",
    "fig3d.savefig(\"loss_surface_3d.pdf\")\n",
    "fig2d.savefig(\"loss_surface_contour.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5x4lhIcyyt3"
   },
   "outputs": [],
   "source": [
    "# MLP - iid - m=50 experiment\n",
    "mlp_iid_m50 = copy.deepcopy(mlp)\n",
    "acc_mlp_iid_m50 = fed_avg_experiment(mlp_iid_m50, num_clients_per_round=50, \n",
    "                                 num_local_epochs=1,\n",
    "                                 lr=0.05,\n",
    "                                 client_train_loader = iid_client_train_loader,\n",
    "                                 max_rounds=100,\n",
    "                                 filename='./acc_mlp_iid_m50')\n",
    "print(acc_mlp_iid_m50)\n",
    "np.save('./acc_mlp_iid_m50.npy', acc_mlp_iid_m50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4NeL5U4zKDS"
   },
   "outputs": [],
   "source": [
    "# MLP - non-iid - m=10 experiment\n",
    "mlp_noniid_m10 = copy.deepcopy(mlp)\n",
    "acc_mlp_noniid_m10 = fed_avg_experiment(mlp_noniid_m10, num_clients_per_round=10, \n",
    "                                 num_local_epochs=1,\n",
    "                                 lr=0.05,\n",
    "                                 client_train_loader = noniid_client_train_loader,\n",
    "                                 max_rounds=300,\n",
    "                                 filename = './acc_mlp_noniid_m10')\n",
    "print(acc_mlp_noniid_m10)\n",
    "np.save('./acc_mlp_noniid_m10.npy', acc_mlp_noniid_m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0MeL-jQzXd7"
   },
   "outputs": [],
   "source": [
    "# MLP - noniid - m=50 experiment\n",
    "mlp_noniid_m50 = copy.deepcopy(mlp)\n",
    "acc_mlp_noniid_m50 = fed_avg_experiment(mlp_noniid_m50, num_clients_per_round=50, \n",
    "                                 num_local_epochs=1,\n",
    "                                 lr=0.05,\n",
    "                                 client_train_loader = noniid_client_train_loader,\n",
    "                                 max_rounds=300,\n",
    "                                 filename='./acc_mlp_noniid_m50')\n",
    "print(acc_mlp_noniid_m50)\n",
    "np.save('./acc_mlp_noniid_m50.npy', acc_mlp_noniid_m50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR4UdghyGNCN"
   },
   "source": [
    "## CNN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQKqbwx6413q"
   },
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)\n",
    "print(\"total params: \", num_params(cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEuqsiF3GkXC"
   },
   "outputs": [],
   "source": [
    "# CNN - iid - m=10 experiment\n",
    "cnn_iid_m10 = copy.deepcopy(cnn)\n",
    "acc_cnn_iid_m10 = fed_avg_experiment(cnn_iid_m10, num_clients_per_round=10, \n",
    "                                 num_local_epochs=5,\n",
    "                                 lr=0.01,\n",
    "                                 client_train_loader = iid_client_train_loader,\n",
    "                                 max_rounds=100,\n",
    "                                 filename='./acc_cnn_iid_m10')\n",
    "print(acc_cnn_iid_m10)\n",
    "np.save('./acc_cnn_iid_m10.npy', acc_cnn_iid_m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0Eo_EYbGTfY"
   },
   "outputs": [],
   "source": [
    "# CNN - iid - m=50 experiment\n",
    "cnn_iid_m50 = copy.deepcopy(cnn)\n",
    "acc_cnn_iid_m50 = fed_avg_experiment(cnn_iid_m50, num_clients_per_round=50, \n",
    "                                 num_local_epochs=5,\n",
    "                                 lr=0.01,\n",
    "                                 client_train_loader = iid_client_train_loader,\n",
    "                                 max_rounds=100,\n",
    "                                 filename='./acc_cnn_iid_m50')\n",
    "print(acc_cnn_iid_m50)\n",
    "np.save('./acc_cnn_iid_m50.npy', acc_cnn_iid_m50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EUw04QbHN9s"
   },
   "outputs": [],
   "source": [
    "# CNN - non-iid - m=10 experiment\n",
    "cnn_noniid_m10 = copy.deepcopy(cnn)\n",
    "acc_cnn_noniid_m10 = fed_avg_experiment(cnn_noniid_m10, num_clients_per_round=10, \n",
    "                                 num_local_epochs=5,\n",
    "                                 lr=0.01,\n",
    "                                 client_train_loader = noniid_client_train_loader,\n",
    "                                 max_rounds=200,\n",
    "                                 filename='./acc_cnn_noniid_m10')\n",
    "print(acc_cnn_noniid_m10)\n",
    "np.save('./acc_cnn_noniid_m10.npy', acc_cnn_noniid_m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gICkrXpMHdZT"
   },
   "outputs": [],
   "source": [
    "# CNN - non-iid - m=50 experiment\n",
    "cnn_noniid_m50 = copy.deepcopy(cnn)\n",
    "acc_cnn_noniid_m50 = fed_avg_experiment(cnn_noniid_m50, num_clients_per_round=50, \n",
    "                                 num_local_epochs=5,\n",
    "                                 lr=0.01,\n",
    "                                 client_train_loader = noniid_client_train_loader,\n",
    "                                 max_rounds=100,\n",
    "                                 filename='./acc_cnn_noniid_m50')\n",
    "print(acc_cnn_noniid_m50)\n",
    "np.save('./acc_cnn_noniid_m50.npy', acc_cnn_noniid_m50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZaLNsaS00jV"
   },
   "outputs": [],
   "source": [
    "# view_10(x_debug[:10].to(cpu), torch.argmax(model(x_debug),dim=1)[:10].to(cpu))\n",
    "\n",
    "# m = CNN().to(cuda)\n",
    "# m.train()\n",
    "# lr = 0.01\n",
    "# opt = torch.optim.SGD(m.parameters(), lr)\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     for (t, (x,y)) in enumerate(train_loader):\n",
    "#         x = x.to(cuda)\n",
    "#         y = y.to(cuda)\n",
    "#         opt.zero_grad()\n",
    "#         out = m(x)\n",
    "#         loss = criterion(out, y)\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "\n",
    "#         if (t%100 == 0):\n",
    "#             print(\"epoch {}, step {}, loss: {}\".format(epoch, t, loss))\n",
    "\n",
    "#     print(\"running validation\")\n",
    "#     acc = validate(m)\n",
    "#     print(\"epoch {} validation acc: {}\".format(epoch, acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FedAvg",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
